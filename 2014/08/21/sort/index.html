<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Jin › 第八篇-Data Structures and Algorithm Analysis in C-第七章笔记</title>
  <meta name="author" content="Jin Liu">
  
  <meta name="description" content="在看Data Structures and Algorithm Analysis in C: Second Edition 第七章SORTING，以下记录自己对SORTING新的理解
SORTING
本章主要介绍对一个组元素进行排序，简单起见，假设元素都是整数，并且假设排序能够在内存中完成（内排），不能在内存中完成的排序也非常重要——外排，会在最后一章讲解">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="第八篇-Data Structures and Algorithm Analysis in C-第七章笔记"/>
  <meta property="og:site_name" content="Jin"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Jin" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-32857089-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>

</head>


<body>
  <header id="header"><div class="meta inner">
  <h1><a href="/">Jin</a></h1>
  <h2><a href="/">Newer@Computer</a></h2>
  <nav id="main-nav">
    <ul>
      
      <li><a href="/about">关于我</a></li>
      
      <li><a href="/archives">文章归档</a></li>
      
      <li><a href="/links">相关链接</a></li>
      
    </ul>
    <div class="clearfix"></div>
  </nav>
</div>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  <div class="post-content">
    <header>
      
  
    <h1 class="title">第八篇-Data Structures and Algorithm Analysis in C-第七章笔记</h1>
  

      
      <time datetime="2014-08-21T08:07:50.000Z">8月 21 2014</time>
      
    </header>
    <div class="entry">
      
        <p><em>在看Data Structures and Algorithm Analysis in C: Second Edition 第七章SORTING，以下记录自己对SORTING新的理解</em></p>
<h1 id="SORTING">SORTING</h1>
<p>本章主要介绍对一个组元素进行排序，简单起见，假设元素都是整数，并且假设排序能够在内存中完成（内排），不能在内存中完成的排序也非常重要——外排，会在最后一章讲解<br><a id="more"></a></p>
<h2 id="主要需要掌握：">主要需要掌握：</h2>
<ul>
<li>有一些简单地排序算法，时间复杂度为O(n^2)，比如插入排序</li>
<li>Shellsort，非常容易实现，时间复杂度为O(n^2)，在实际应用中也很有效</li>
<li>有一些更复杂的排序算法，时间复杂度为O(n logn)</li>
<li>所有时间复杂度为Ω(n logn)的通用排序算法的比较</li>
<li>排序算法中有很多有意思并且重要的代码优化和代码设计的方法，排序算法的分析可以很明确</li>
</ul>
<h2 id="关键点：_"><strong>关键点： </strong></h2>
<ul>
<li>Preliminaries<ul>
<li>这里所有描述的排序算法都是可以互换的：所有函数都是传入一个包含所要排序元素的数组，并且和一个代表数组大小的整数</li>
<li>假设n，传入数组的大小被检查是合法的，某一些算法可能在数组0位置放置一个哨兵（sentinel），我们假设数组位置从0到n，实际存放位置从1开始</li>
<li>对元素的操作只有’&gt;’，’&lt;’，’=’</li>
</ul>
</li>
<li>Insertion Sort<ul>
<li>The Algorithm<ul>
<li>Insertion sort包括n-1步，从p=2到p=n，insertion sort保证位置1到位置p都排好序</li>
<li>Insertion sort保证从位置1到位置p-1的元素已经排好序</li>
<li>Insertion sort基本策略是，在第p步，在位置1到p找到第p个元素的正确位置</li>
<li>实现：array位置0放一个哨兵，值取最小（增序排序），对于第p步，将位置p的元素存放在tmp中，然后所有在位置p前面的比位置p上元素大的元素以此向后移一个位置，最后将tmp放在正确地位置</li>
</ul>
</li>
<li>Analysis of Insertion Sort<ul>
<li>由于2层嵌套循环，每一层循环迭代n次，所以insertion sort时间复杂度为O(n^2)</li>
<li>由于该复杂度也是该算法的上限，因为降序的输入就会使得复杂度达到O(n^2)</li>
<li>另外，当输入是已经排好序的，那么运行时间为O(n)，事实上，如果输入已经块排好序了，那么整个排序很快就会完成</li>
<li>由于最坏最好情况差别太大，所以需要计算一下平均情况，平均情况为为Θ(n^2)，很多其他排序算法都是如此</li>
</ul>
</li>
</ul>
</li>
<li>A lower bound for simple<ul>
<li>Sorting Algorithms<ul>
<li>inversion：inversion是指，在数组中任意一对元素（i，j）有这样的性质：i<j，但是a[i]> a[j]</j，但是a[i]></li>
<li>对于insertion sort，inversion的数量等于交换操作执行的次数()，因为一次交换就消除一个inversion</li>
<li>insertion sort的运行时间为O(I + n)，I是inversion的个数，n表示至少遍历一次数组</li>
<li>insertion sort的平均时间可以根据inversion的平均个数来计算<ul>
<li>average的定义<ul>
<li>没有重复的元素</li>
<li>由于没有重复元素，假设输入的数组中的元素就是由前n个整数组成的（inversion只跟相对大小有关），n为数组大小，并且每个整数出现的概率相同</li>
<li>得到平均inversion的个数为n(n - 1)/4<ul>
<li>证明：对于一个数组L和他的倒序数组Lr，很明显，任意一堆数必在L或在Lr中组成inversion，而且只能在L和Lr中存在一次，而两个数组合起来，总共的inversion为n(n - 1)/2，所以平均个数就为n(n - 1)/4</li>
</ul>
</li>
<li>这说明insertion sort平均时间复杂度为O(n^2）</li>
<li>也说明只交换相邻元素的排序算法的时间复杂度下限为O(n^2）<ul>
<li>Any Alogrithm that sorts by exchanging adjacent elements requires Ω(n^2) time on average</li>
<li>insertion sort通过tmp使用了隐式(implicitly)的swap，因为p位置的元素直接放到最后正确地位置，而不是一个一个和前面的元素交换</li>
<li>这里所分析的adjacent exchange就是类似insertion sort的交换，所有这一类的排序，如冒泡排序(bubble sort)和选择selection sort，都是这样的交换方式</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>这里介绍的下限向我们证明，为了实现时间复杂度低于O(n^2)的排序算法，必须能够比较两个距离很远的元素，并且能够交换它们的位置——这就是改进算法的思路</li>
<li>那些通过消除inversion的排序算法，为了更高效，则必须通过一次交换能够消除多个inversion</li>
</ul>
</li>
<li>Shellsort<ul>
<li>希尔排序，根据其发明者命名，最初打破排序算法二次时间复杂度的瓶颈的算法之一，这在它被发明几年之后才被证明</li>
<li>它的思路就是上文提到的比较不相邻的元素(elements that are distance)</li>
<li>所比较的不相邻元素之间的距离随着算法进行一步步缩小，直到最后一步，回归到相邻元素的比较上来，因此shell排序也被叫做diminishing increment sort(减少增量排序)</li>
<li>shell排序使用一个序列h1，h2，…，ht（叫做增量序列increment sequence），任意增量序列都使用，只要h1=1，不过显然某些序列效果更好</li>
<li>假设对于算法使用增量hk，那么这一步之后，对于数组中的任意i，都有a[i] &lt; a[i+hk]（在数组下标有意义的情况下），所有隔hk的元素都排好序，这时数组叫做hk-sorted</li>
<li>shell排序一个很重要的性质：hk-sorted的数组经过h(k-1)排序后[h(k-1)小于hk]，此时数组为h(k-1)-sorted，同时保持hk-sorted</li>
<li>shell排序的实现不能用哨兵(sentinel)，因为有多个头头</li>
<li>shell建议使用的增量序列为ht = └n/2┘，hk = └h(k+1)/2┘，存在一些序列可以大大提高排序算法的效率</li>
<li>shell排序实现的策略<ul>
<li>在对于任意i，i属于hk+1，hk+2，…，n，将这些位置上的元素放到其正确的位置i-hk，i-2*hk等等，这实际上是在所有相邻hk的元素上进行insertion sort，了解这一点对分析shell排序很重要</li>
</ul>
</li>
<li>Worst-Case Analysis of shell sort<ul>
<li>shell排序实现简单，但是分析复杂，因为算法的运行时间跟增量序列有关，而且证明也收到增量序列的影响</li>
<li>shell排序算法的平均运行时间是一个存在很久的开放问题</li>
<li>THEOREM <ul>
<li>使用shell的增量序列，在最坏的情况下，shell排序的时间复杂度为Θ(n^2)<ul>
<li>lower bound</li>
<li>构造一个使用shell排序需要的时间复杂度为n^2的数组，注意，因为这个THEOREM为最坏的情况下，这个条件很重要，因为可以认为最坏的情况比我们构建的数组排序需要的时间要长，所以如果我们构造出数组排序的时间复杂度为n^2，那么在最坏的情况这个条件下，就符合复杂度符号Ω的定义了</li>
<li>假设n为2的整数次幂，则除了最后一个增量为1外，所有的增量序列为偶数</li>
<li>假设构造输入数组如下：前n/2个最小元素存放在数组奇数位置上，后n/2个最小元素（前n/2个最大元素）存放在数组偶数位置上，因为增量为偶数，所以知道最后一次排序，前n/2个最小元素任然在奇数位置上，后n/2个最小元素任然在偶数位置上</li>
<li>那么在进行最后一次排序前，第i（i &lt;= n/2 ）小的元素在数组中的位置为2i-1，将第i小的元素放到正确地位置上则需要i-1次移动，那么最后一次排序则至少需要移动Ω(n^2)次，等差数列求和，i从1到n/2</li>
<li>upper bound</li>
<li>通过观察，当增量为hk时的shell排序包含了hk组元素个数大致为n/hk的insertion sort，根据insertion sort的二次时间复杂度，那么增量为hk时，shell排序的时间复杂度为O(hk <em> (n/hk)^2)，即O(n^2 / hk)。将shell排序的所有增量序列的时间复杂度相加可得总和为O(n^2 </em> A)，其中A为则为那个量序列倒数的和，而shell增量序列为首项为1，公比为1/2的等比数列，所以&lt;2，所以的到得时间复杂度为O(n^2)</li>
<li>shell的增量序列的问题是不一定是互质的，因此小的增量影响很小。Hibbard建议的序列为1，3，7，…，2^k-1，实际应用中效果更好，尽管和shell的增量序列几乎一样，但是Hibbard的增量之间没有公因数，而对于这个增量序列，在最坏情况下，时间复杂度为Θ(n^(3/2))，证明略</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Heapsort<ul>
<li>如第六章所讲，有限队列priority queues能够在O(nlog n)的时间复杂度下排序。这种基于priority的排序叫做heapsort，是我们至今看到的大O时间复杂度最好的排序算法，但是在实际中，它比使用Sedgewick的增量序列的Shellsort要慢</li>
<li>堆排序基本策略是构造n个元素的二分堆，而构造二分堆的平均时间复杂度为O(n)，然后执行n个delete_min操作，将每次操作获得的当前最小元素在第二个数组中排列好，最后将第二个数组中排好序的元素复制到原来的数组中，由于delete_min的时间复杂度为O(log n)，所以总的时间复杂度为O(nlogn)</li>
<li>堆排序的主要问题是它用到了而外的数组，因此，内存的需求为两倍。这在某些情况下就是问题了，注意将第二个数组中的元素复制回第一个数组的时间为O(n)，这不会明显影响算法时间。主要问题是空间问题</li>
<li>一个解决空间问题避免使用第二个数组的方法：因为delete_min操作之后，heap数组收缩1（因为一个元素delete掉了），因此heap数组最后一个位置可以用来存放刚刚删除掉的最小的元素，使用这个策略，最后将得到一个降序排列的数组，如果想得到一个增序排列的数组，我们可以将堆的ordering property改成父节点的值比子节点的值大，这样我们得到了一个max heap</li>
</ul>
</li>
<li>Mergesort<ul>
<li>Mergesort在最坏情况下的时间复杂度为O(nlogn)，比较次数也是接近最优，并且它是一个递归算法的很好的例子</li>
<li>Mergesort的基本操作就是合并两个已经排好序的数组，因为数组已经排好序，而且如果输出结果存放在第三个数组中，那么这个操作可以通过遍历一次输入数据而完成</li>
<li>最基础的mergesort算法：两个数组a，b作为输入，一个数组c作为输出，而且有三个指针aptr，bptr，cptr，指针分别初始化为三个数组的首地址。输入数组a，b中较小的那个元素a[aptr]或者b[bptr]复制到输出数组c的下一个位置。当任意一个输入数组的元素已经排完，另一个输入数组的剩下全部元素都复制到c数组</li>
<li>合并两个排列好的数组的时间复杂度为线性的，因为最多需要n-1次比较，n是元素个数（每一次比较都会添加一个元素到c数组中，除了最后一次比较，可以将最后两个元素都放到c数组中，显然经过n-1次比较，c数组就满了，也排好序了）</li>
<li>对mergesort的描述：如果n=1，只有一个元素需要排序；否则，递归的mergesort（这里mergesort是个动词）前半部分和后半部分数组，而递归的mergesort前半部分和后半部分这个结果是得到了两个分别排好序的前半部分和后半部分，然后将两个排好序的前半部分和后半部分通过上述的排序方法就可以将两部分合并排序得到最终结果</li>
<li>Mergesort是典型的分治算法（divide-and-conquer），分（divide）就是将大问题分成一份份小问题并且递归地解决他们，治（conquer）就是将小问题的结果合并</li>
<li>Mergesort实现需要注意：因为要用到辅助数组，如果这个数组在每一个递归调用中都分配，这样在任何时候都有大约logn个数组（数组大小应该是n，因为每个递归函数都是一样的，而且要满足最后一次合并的空间要求），而如果在merge过程中动态分配和回收内存，这样又太耗时。而由于merge是每次递归的最后一步，在任何时刻，只有一个merge执行，那么可以分配一个全局的辅助数组，大小为n+1（从1开始存放元素）</li>
<li>Analysis of Mergesort<ul>
<li>Mergesort是一个分析递归程序相关技巧的经典例子，很显然，Mergesort不那么简单地可以非递归的方式写出来（但是它可以）</li>
<li>所以为了分析它的时间复杂度，我们写出一个运行时间的递推关系，假设n为2的幂，这样被分割的数组都有偶数个元素，如果n=1，那么运行时间为常数，假设为1；当n&gt;1，n个元素的mergesort的运行时间等于两个递归调用分别排列n/2个元素的时间加上合并两个排好序的数组的时间（线性）<ul>
<li>T(1) = 1</li>
<li>T(n) = 2T(n/2) + n</li>
<li>以上是标准的递推关系，不难推出T(n) = nlogn + n = O(nlogn)</li>
</ul>
</li>
<li>尽管mergesort时间复杂度为O(nlogn)，但是它并不适用于内排序，主要的原因是合并两个排好序的数组需要额外的线性内存空间，并且数组之间复制元素也是相当耗时的，尽管可以通过编程消除这些复制的影响，尽管可以实现非递归的mergesort，更多地内排序应用都用quicksort来排序，而mergesort是大多数外排序算法的基石</li>
</ul>
</li>
</ul>
</li>
<li>Quicksort<ul>
<li>正如这个算法的名字，quicksort是实际中已知最快的排序算法，算法平均运行时间为O(nlogn)。这个算法非常快，主要是因为一个紧凑而高度优化的内部循环，在最坏情况下，这个循环的时间复杂度为n^2，但是可以不费力地指数级的降低这种最坏情况的可能。</li>
<li>Quicksort很容易理解并且证明，尽管很多年，quicksort在理论界被认为是高度优化的算法，但是实际上很难正确地编码实现（由于FORTRAN语言的原因）</li>
<li>Quicksort类似mergesort，是分治递归算法，quicksort排列一个数组S的四个基本步骤如下：<ul>
<li>如果S中的元素为0个或1个，则返回</li>
<li>任选S中的一个元素v，它被叫做pivot（中心点）</li>
<li>将S - {v}（S中剩余的元素）分割成两个不想交的集合S1={x ∈ S-{v} ︳x≤v}，S2={x ∈ S-{v} ︳x≥v}</li>
<li>返回quicksort(S1)+v+quicksort(S2)</li>
<li>由于第三步分割，对于和中性点pivot相等的元素的处理含糊不清，所以，这个处理就变成了编码时的设计选择。好的实现是尽量高效的处理这种情况。直观地来说，我们可能希望和pivot相等的元素，一半分进S1，而另一半则分进S2，正如我们希望二分查找树平衡一样</li>
</ul>
</li>
<li>很明显quicksort可以正确排序，但是为什么它比mergesort快，这一点并不明显。和mergesort一样，quicksort递归的解决两个子问题然后加上额外的线性时间的工作，但是，和mergesort不同的是，quicksort的两个子问题并不保证规模相同（equal size），这可能是影响效率的。quicksort比mergesort快的原因是因为实际上分割S这一步可以高效的在原来的数组上完成，这一点带来的效率提升比quicksort难以保证相同规模的递归调用带来的效率降低更明显</li>
<li>Quicksort实现，主要是第二步和第三步，这里的代码是根据广泛的分析和实际的研究得出的高效的实现，虽然轻微的偏差可能使这里实现的方法引起令人惊讶的坏得结果<ul>
<li>Picking the pivot<ul>
<li>尽管根据算法的描述，不管选择哪个元素作为pivot，算法都是可行的，但是显然，选择某些元素明显要比选择其他元素要好<ul>
<li>A Wrong Way<ul>
<li>最流行，简单的选择就是选择第一个元素作为pivot</li>
<li>如果输入元素是随机的，那么这个方法是可行的</li>
<li>如果输入元素是预排序的或者是倒序的，那么这个方法是非常糟糕的，因为事实上，所有元素全部分到了S1或者S2，更糟的是，这种情况在接下来的递归调用中会持续的发生。实际情况是，如果用这种方法，并且输入数组是预排序的，那么quicksort花二次方时间，而实际上什么都没做，这太尴尬了<br>＋ 此外，预排序的输入（或者输入的一大部分是预排序的）这种情况是很常见的，所以这种方法绝对是一种可怕的想法而且它应该立即被抛弃，另一种方案是选择前两个不同的元素中较大的那个作为pivot，但是这中方案和选择第一个元素作为pivot有着同样的效果，也不要使用这种方案</li>
</ul>
</li>
<li>A Safe Maneuver<br>  ＋ 一个安全的方法是随机选择中心点（pivot）<br>  ＋ 这种方法通常是绝对安全的，除非随机数生成器有缺陷（这点不像你想像的那么不常见），因此随机选择中心点会持续的给出不好的分割这一点一般不太可能<br>  ＋ 另一方面，随机数生成是很耗时的，因此它并不能减少整个算法的平均运行时间</li>
<li>Median-of-Three Partitioning<br>  ＋ 中位数分割法n个元素中的中位数是指这些元素中第┌n/2┐大的元素<br>  ＋ 中心点选择的最好方法是选择整个输入元素的中位数，不幸的是，中位数很难计算，而且这个过程会大大降低quicksort的效率<br>  ＋ 一个好的估计方法是，随机选择三个元素，并且用这三个元素的中位数来代替<br>  ＋ 实际证明，随机选择没有太大帮助，因此可以选择输入数组中最左边，最右边，和中间三个元素的中位数作为pivot<br>  ＋ 中位数分割法显然消除了预排序的输入的影响而且提升quicksort排序时间达5%，因为中位数为中间那个数，所以分割的两个数组中的元素个数相等</li>
</ul>
</li>
</ul>
</li>
<li>Partitioning Strategy<br>  ＋ 实际应用中有几种分割策略，这里讨论的已知可以给出很好的排序结果，它很容易错误的实现或者效率不高<br>  ＋ 第一步是将pivot元素和数组最后一个元素交换位置，然后定义i从指向第一个元素开始，j从指向倒数第二个元素开始<br>  ＋ 现在假设输入中没有相等元素，后面考虑出现相同元素的情况<br>  ＋ 作为一个有限制的列子，我们的算法需要做正确的事情，如果所有的元素都是不想等的，你会发现错误的实现是多么容易产生<br>  ＋ 我们想做的是将所有小于pivot的元素移到数组左边，所有大于pivot 的元素移到数组右边<br>  ＋ i从左向右移动，跳过那些比pivot小的元素；j从右向左移动，跳过那些比pivot大的元素。当i，都停下来的时候，i指向了一个比pivot大的元素，j指向了一个比pivot小的元素，如果此时i&lt;j，将这两个元素交换位置，这样的效果是将一个大的元素移到右边，一个小的元素移到了左边。重复上述过程，直到i，j相交<ul>
<li>当i和j相交之后，分割的最后一步是交换pivot（数组最后一个元素）和i指向的元素，交换后，我们知道所有小于i位置上的元素都比pivot小，因为p位置上的元素要么开始就比pivot小，要么原来的比pivot大的元素被交换到右边去了。对于大于i位置的元素同理都比pivot大</li>
<li>一个很重要的细节需要考虑的是，如何处理那些和pivot值相等的那些元素。这个问题概括成当碰到和pivot相等的元素时，i和j是否应该停下来。直观地看，i和j应该做同样地事，因为否则的话，这个分割步骤就是有偏的（biased），例如，如果i停下来，而j不停下来，那么所有和pivot相等的元素都会分到右边去（S2）<ul>
<li>为了发现好的处理方法，我们假设数组中所有元素值都是一样的，如果i和j都停下来，则元素间会产生很多次交换，尽管这看起来是无用的，但是好处是ij在中间位置相交，所以，当pivot被交换到中间位置时，分割出的两个部分大小相等。mergesort的分析告诉我们这种方法得到的总共的运行时间为O(nlogn)</li>
<li>如果ij都不停下来，而且实现的时候保证ij不会超过数组边界，那么将不会进行swap操作。尽管这看起来很好，但是pivot会和最后i位置上的元素交换，而i此时指向最后一个或者倒数第二个元素（根据不同的实现），这将造成非常不平衡的两个子文件（subfile），如果所有元素都是一样的，那么运行时间为O(n^2)，循环遍历数组的时间（应该是等差数列1，2，…,n的和），这个选取第一个元素作为中间点pivot效果是一样的，他它花了二次项时间却什么都没做</li>
<li>因此，我们发现做一些没有意义的的swap操作（ij都停下来）并且得到两个平衡的subfile这种方案更可取，这种方法是可能的四种方案（ij分别停或者不停），只有ij都停下来这一种方案在所有输入元素值都相同的情况下不需要二次方的时间来完成排序</li>
<li>乍一看，担心一个文件全部都是相同元素这一点是很愚蠢的，毕竟，怎么会有人想要对5,000个相同元素进行排序呢？然后，因为quicksort是递归的，假设有100,000个元素，其中有5,000个元素相同，最终quicksort的递归调用函数会在只有这5,000个相同元素的子集（5,000个相同元素相对于所有元素来说偏小，偏大或者位于中间位置）上操作，这种情况下，保证相同元素的排序效率就很重要了</li>
</ul>
</li>
</ul>
</li>
<li>Small Files<ul>
<li>对于非常小的输入文件（n≤20），quicksort效率没有insertion sort高，而且因为quick sort是递归的，这种低效的情况很频繁。一个常见的解决方案是，对于小文件，不使用quicksort，而是使用排序小文件更有效的算法（如插入排序insertion sort）。一个更好地idea是当（quicksort递归到每一组都是小文件）文件只是稍微的unsorted（invertion对很少）时，这时使用insertion sort，因为insertion sort对于那种快排好序的序列有更高的效率，使用这种策略，相对于直接使用quicksort要更高效，大概节省15%的时间，一个好的cutoff值是n=10（表示当quicksort递归到每个小数组都只有10个元素时，就不在递归调用将数组分得更小），任何n=5到n=20都产生差不多的效果，这种cutoff也解决了很多退化现象（nasty degenerate cases），比如递归到数组只包含1到2个元素的时候</li>
</ul>
</li>
</ul>
</li>
<li>Analysis of Quicksort<ul>
<li>正如mergesort，quicksort也是递归的，因此，需要一个递推公式，我们的分析假设中心点pivot是随机选取（而不是Media-of-Three分割法选取），并且不截断小文件。</li>
<li>我们假设T(0)=T(1)=0，这一点跟mergesort类似。quicksort的运行时间等于两个递归调用的时间和加上分割数组这一步的线性时间（选择pivot所花的时间是常量），于是可以得到基础的运行时间关系：T(n)=T(i)+T(n-i+1) + cn，这里i等于S1（左边部分）中元素的个数，这里就可以分为三种情况了<ul>
<li>Worst-Case Analysis<ul>
<li>每一次递归选择的pivot都是最小元素，那么i=0，假设忽略T(0)=1，那么递推公式为：T(n)=T(n-1) + cn，n&gt;1，很容易可以推出T(n)=O(n^2)，正如前面分析的不平衡分割的结果一样</li>
</ul>
</li>
<li>Best-Case Analysis<ul>
<li>最好情况下，pivot选择中位数，为了简化证明，假设分割的两个子数组大小一样，因为我们感兴趣的是大O复杂度，所以在最好情况这个条件下，假设子数组大小一样是可以接受的（最好的情况只会比现在假设的情况更好），此时递推公式为：T(n)=2T(n/2)+cn，不难得到T(n)=O(nlogn)。实际上分割并没有那么严格到要两个子数组大小完全一样，就算99%的元素被分在一边，1%的元素被分在另一边，调用的深度还是在100logn，所以运行的时间还是O(nlogn)</li>
</ul>
</li>
<li>Average-Case Analysis<ul>
<li>平均时间复杂度最难。在平均情况下，我们假设任何大小的S1都是等可能的，因此概率都为1/n，这种假设对于所述的pivoting和partitioning strategy是正确地，但是其他的情况不一定，那么不能保证随机子数组大小的分割方法不适合这里的概率假设，有意思的是这里的pivoting和partition strategy在实际应用中效率更低</li>
<li>根据假设递推公式变为：T(n)=2/n*[∑T(i)] + cn（i从0到n-1，这个式子也是根据T(n)=T(i)+T(n-i+1)得到的，将i从0到n-1代入这个式子，然后除以n就可以得到），通过递推公式可以得到T(n)=O(nlogn)，证明过程省略</li>
</ul>
</li>
</ul>
</li>
<li>事实上，quicksort的分析远比上述要深入，上述实现（实现这一节被省略了）的各种优化方式和当数组中有相同元素时的优化都被证明是正确的，但是这个证明太复杂，涉及复杂的递推和数学知识</li>
</ul>
</li>
<li>A Linear-Expected-Time Algorithm for Selection<ul>
<li>Quicksort可以被修改用来解决selection问题，我们知道用priority queue可以找到第k大（或小）的元素，并且时间复杂度为O(n + klogn)，如果我们寻找中位数，那么时间复杂度为O(nlogn)</li>
<li>因为用quicksort可以在O(nlogn)的时间复杂度下排序，我们可以期望能够得到一个更好地解决selection问题，quickselect和quicksort几乎一样，我们假设|Si|表示Si中元素个数，我们要找S中第k小的元素，quickselect的基本步骤为：<ul>
<li>如果|S|=1，而且k=1，那么返回S中的那个元素，如果有CUTOFF，而且|S|≤CUTOFF，那么返回S中的第k个元素</li>
<li>选择一个中心点v，v∈S</li>
<li>将S - {v}按照quicksort的方式分割成S1和S2</li>
<li>如果k≤|S1|，那么第k小的元素肯定在S1中，这种情况下，递归调用并且返回quickselect(S1, k)，如果k=1+|S1|，那么pivot就是第k小的元素，那么我们返回pivot。否则第k小的元素肯定在S2中，那么递归调用并且返回quickselect(S2,k-|S1|-1)，注意这里的quickselect(S2,k-|S1|-1)</li>
</ul>
</li>
<li>和quicksort不同的是，在每一次分割后，quickselect只发起一次递归调用，而不是两次</li>
<li>最坏情况下，分割的两个子数组中有一个为空，这个时候，一次递归调用并没有节省时间，此时复杂度为O(n^2)</li>
<li>平均情况下，S1的大小是等概率的，此时时间复杂度为O(n)，这个分析跟平均情况下地quicksort的分析类似</li>
<li>这个算法的实现，如果用median-of-three的pivotaing strategy，则最坏情况出现的可能性极小；而通过仔细的选择中心点，我们可以消除最坏情况二次时间的可能性，并且确保算法时间复杂度为O(n)，不过这样做开销是很大的，可能的算法在理论界比较感兴趣</li>
</ul>
</li>
</ul>
</li>
<li>Sorting Large Structures<ul>
<li>整章都假设要排序的元素是整数。经常的，我们需要通过一些key来排列大的结构，比如说我们可能有工资单记录，每一条记录都包括，姓名，地址，电话号码，财务信息如工资，税务信息等。我们可能想要根据其中某一个key（比如说姓名）来进行排序，我们所述的算法都是通过swap来进行的，但是swap大型结构代价是很高的，所以实际中的解决方案是数组中存放结构的指针，swap也是对指向结构的指针进行操作的，这就叫做indirect sorting</li>
</ul>
</li>
<li>A General Lower Bound for Sorting<ul>
<li>尽管我们已经有了O(nlogn)的排序算法，但是我们不清楚这是否是我们能得到的最好的算法。我们可以证明，在最坏的情况下，只通过比较操作来排序的任意排序算法的比较次数（时间复杂度）都为Ω(nlogn)</li>
<li>将证明：<ul>
<li>任意只通过比较操作来排序的排序算法在最坏的情况下需要┌log n!┐次比较，在平均情况下需要log n!次比较，我们假设所有元素都不相等</li>
</ul>
</li>
<li>Decision Trees<ul>
<li>decision tree是用来证明下界（lower bound）的一种抽象方法。在这里，决策树是一个二分树，每一个节点表示一些和比较结果相符的排序组成的集合。比较的结果是树种连接节点的树枝</li>
<li>任何只通过比较来排序的算法都可以表示成一个决策树，不同的算法会由不同的决策树</li>
<li>某个算法的比较次数等于该算法对应的决策树的最深叶子节点的深度</li>
<li>平均比较次数等于决策树中叶子节点的平均深度</li>
<li>引理1：<ul>
<li>若T是深度为d的二分树，那么T最多有2^d个叶子节点</li>
<li>证明：归纳法，当d=0时，最多只有一个叶子节点（根节点），此时根节点不是叶子节点，根据归纳假设，根节点的左右子树（深为n-1）最多可能有2^(d-1)个叶子节点，所以深为d最多有2^d个叶子节点</li>
</ul>
</li>
<li>引理2：<ul>
<li>有L个叶子节点的二分树的深至少为┌logL┐</li>
</ul>
</li>
<li>定理1：<ul>
<li>在最坏情况下，任何只通过元素之间comparison（比较）的排序算法，至少需要进行┌log n!┐次比较</li>
<li>证明：因为排列n个元素的决策树含有n！和叶子节点（每个叶子节点包含一种结果），根据前面的引理，定理可证</li>
</ul>
</li>
<li>定理2：<ul>
<li>任何只通过元素之间比较的排序算法，需要Ω(n logn)次比较</li>
<li>证明：数学推导log n！ &gt;= n/2logn - n/2 = Ω(n logn)</li>
</ul>
</li>
<li>引理3：<ul>
<li>任意有L个叶子节点的二分树的平均深度至少为log L</li>
</ul>
</li>
<li>这种类型的下界讨论，当被用来证明最坏情况的结果时，通常被叫做信息理论下界。一般的定理：如果有P个可能的结果，并且解决问题的步骤中的答案YES/NO，那么任意解决这个问题的算法都需要┌log P┐步</li>
</ul>
</li>
</ul>
</li>
<li>Bucket Sort<ul>
<li>尽管我们证明了在最坏情况下任意通过比较的一般的排序算法需要Ω(n logn)的时间来排序，但是在某些特殊情况下任然可能在线性时间内排序</li>
<li>桶排序是一个简单的例子，桶排序能够工作有几个条件，它需要一些额外的信息<ul>
<li>输入a1，a2，…，an只含有小于m的正整数（排序的元素可以扩展复杂化），在这个条件下，算法的策略：<ul>
<li>分配一个count数组，大小为m，初始化数组元素为0</li>
<li>因此count数组含有m个地址，或者桶bucket，而且初始化的时候它们是空的</li>
<li>当读取ai时，count[ai]值加1。当所有输入元素都读了一遍后，扫描count数组，获得排序后的序列</li>
<li>这个算法的时间复杂度为O(m+n)，当m=n时，复杂度为O(n)</li>
<li>桶排序算法貌似打破了下界限制，但是事实上，它使用了比比较更为复杂的操作，通过将相应桶的值加1操作，实际上这个算法在单位时间内完成了一次m-路（m-way）比较，这个策略和extending hashing（第5章）类似，显然，这不符合下界模型</li>
<li>这个算法，显然让我们可以思考一些问题，对于下界模型，它的限制是很强的，因为一个general-purpose的排序算法并不确定输入就一定是正整数，而只能根据排序信息做排序决定。自然地，如果我们有额外的信息可以利用，我们就需要根据它找到更有效的排序算法，否则这些额外信息可能就浪费了</li>
<li>尽管bucket sort看来微不足道，但是很多情况下，输入都只是一些小的整数，这个时候根本没必要使用quicksort</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Externla Sorting<ul>
<li>至今，讨论的排序算法都是在内存中进行的。然而，很多应用，输入数据很大，不能放到内存中，而外排序就是为了解决输入数据太大这个问题而而设计</li>
<li>Why We Need New Algorithm<ul>
<li>大多数内排算法都利用了内存的直接存取操作，如shellsort在一个单位时间内比较a[i] 和a[i-hk]；使用中位数分割法的quicksort，在常数时间内就能够比较a[left]，a[center]，a[right]的大小。但是当数据在磁带上时，所有的这些操作都不在有效，因为磁带的数据访问方式只能是顺序的；即使数据在磁盘上，效率也会很低，因为磁盘上数据的读取也需要旋转磁盘和移动磁头</li>
<li>如果想看看外排序实际有多慢，可以创建一个不是占据大部分内存空间的随机文件，读取文件并且用一种很高效的排序算法来排序。相对于读取输入数据，排序的时间是无关紧要的，即使排序的时间复杂度为O(nlogn)，读取数据的复杂度为O(n)</li>
</ul>
</li>
<li>Model for External Sorting<ul>
<li>形形色色的大容量存储设备导致外排比内排序更加设备相关（device-dependent）。这里的算法我们考虑磁盘，最严格的存储介质，数据是通过旋转磁带到正确位置获取，磁带只能单向顺序获取数据</li>
<li>我们假设我们至少有3个磁带驱动器来执行排序。其中两个执行排序，第三个是问题简化。如果只有一个磁带驱动，那么我们会碰到问题：任何算法都需要O(n^2)的磁带访问</li>
</ul>
</li>
<li>The Simple Algorithm<ul>
<li>最基础的外排序，使用mergesort。假设我们有四个磁带，Ta1，Ta2，Tb1，Tb2，两个输入磁盘和两个输出磁盘。假设数据初始在Ta1，进一步假设初始内存一次能够容纳（并且排序）m条记录，一个自然的想法是第一步从输入磁带中一次性读取m条记录到内存中，将这m条记录进行内排序，然后交替地讲一次内排序的m条记录记过全部存放到输出磁盘Tb1或Tb2（如第一次的m条排序结果放到Tb1，第二次放到Tb2，第三次又放到Tb1）。我们将每一个排好序的m条记录叫做一个run，当我们将所有输入都分组排好序并且存放到不同输出磁盘上后，我们将所有磁带倒带到起始位置</li>
<li>现在Tb1，和Tb2中包含了runs，我们从Tb1和Tb2中各拿一个run，合并（merge）它们，然后向合并的结（第一次run的两倍长）果写入Ta1，然后我们再从Tb1和Tb2中各拿一个run，合并（merge）它们，然后将合并的结果写入Ta2。我们继续这个过程，将结果交替写入Ta1，和Ta2，直到Tb1或Tb2中一个为空，这是Tb1和Tb2要么都空，要么还有一个run剩余，如果是后一种情况，我们将最后一个run按照之前轮流的规则复制到Ta1或Ta2。然后我们又将四个磁带倒带到初始位置，然后重复相同的步骤，并且这次用a磁带作为输入，b磁带作为输出，并且一个run的长度为4m，我们重复这个步骤直到run的长度变为n</li>
<li>这个算法需要┌log(n/m)┐次循环步骤（pass），加上第一次初始化的步骤，例如如果有13条记录，内存每次可以放3条记录，我们就需要┌log(13/3)┐=3次循环步骤加上第一次初始化的步骤</li>
</ul>
</li>
<li>Multiway Merge<ul>
<li>如果我们有更多多余的磁带，我们通过将2-way merge转换成k-way merge来减少pass次数</li>
<li>合并两个run的步骤是：将inpu磁带倒带到起始位置，然后找到较小的那个元素，并将它优先输出到适合的磁带。如果有k个输入磁带，也是同样地方式，唯一的不同是从k个元素中找到最小元素更麻烦一点。我们可以通过使用priority queue来从这些元素中找到最小的元素。为了找到下一个最小元素，我们对优先队列进行delete_min操作，并将元素放入适当的的输出磁带，如果输出磁带的run还没有完成，那么通过优先队列的insert操作，将元素继续插入到优先队列，知道一条输出磁盘的一条run填满，然后继续填下一个输出磁盘的run，重复这个过程</li>
<li>整个k-way，multiway merge，首先需要第一步初始化步骤，然后需要使用┌logk (n/m)┐（以k为底）次pass，因为run的长度每次增加k倍。例如，我们有13条记录，内存可以存放3条记录，如果一共有6个磁带作为输入输出磁带，那么我们需要┌log3 (13/3)┐ = 2次pass。如果我们有10个磁带，那么k=5，我们需要┌log5 (13/3)┐=1次pass</li>
</ul>
</li>
<li>Polyphase Merge<ul>
<li>k-way merge策略需要2k个磁带，这对于某些应用是禁止的。我们可能通过k+1个磁带达到k-way排序的目的</li>
<li>作为例子，我们将一下，如何通过2+1个磁带完成2-way merge</li>
<li>假设我们有3个磁带，T1，T2和T3，输入在T1，并且初始化得到34个runs。一个可以的方式是分别在T2和T3上放17个runs。因此我们就可以将结果merge到T1上，此时T1上有17个runs（长度增加一倍），现在的问题是所有的runs都在一个磁带（T1）上，我们需要将T1上一部分runs放到另一个磁带上去，然后才能完成第二次merge操作。这就让每原先2k个磁带的每一次pass都增加了半个pass</li>
<li>另一个可选方案是不平衡地分割原先的34个runs，假设我们将21个runs放到T2，并将13个runs放到T3。那么我们可以合并出13个runs（长度增加一倍）到T1。此时我们可以将T1和T3倒带到初始位置，然后合并T1（有13个runs）和T2（有8个runs）到T3上，这时当T2为空时，我们可以合并8个runs，然后T1里面还剩5个runs，T3上有8个runs，我们随后又合并T1和T3，依此类推，知道全部runs合并，排序完成</li>
<li>最初的runs的分配很重要，例如，假如22个runs放在T2，12个runs放在T3，那么第一次合并之后，T1有12个runs，T2有10个runs，再进行一次合并之后，T3有10个runs，T1剩2个runs，接下来的合并就变得很慢了，因为我们此后只能每次合并2个runs了，一直这样重复下去到最后，T2最后还有2个runs，而T1为空，此时我们需要复制一个run到另一个磁带，完成最后一次合并</li>
<li>如果runs的个数为斐波那契数Fn，那么最好的分割方法就是将它分割成另外两个斐波那契数Fn-1和Fn-2。如果不是斐波那契数，我们需要将在原来的runs后面填充一些傀儡（dummy）runs来组成斐波那契数</li>
<li>我们同样可以扩展到k-way merge，这样我们需要构造k个斐波那契数，而这个斐波那契数组定义为F(k)(n) = F(k)(n-1) + F(k)(n-2) + … + F(k)(n-k)。（F(k)(n)表示k阶斐波那契数列的第n个数，初始为F(k)(n)=0，当 0≤n≤k-2，F(n)(k-1)=1）</li>
</ul>
</li>
<li>Replacement Selection<ul>
<li>最后我们讨论的是构造runs，我们以前讨论的是最简单构造runs的策略：读取尽可能多的记录并且将他们排序，将结果写到一些磁带中。这个策略看起来是最好的方法，可是我们意识到，当一条记录写到磁带后，它原本占用的内存又变得可用如果输入数组中的下一个记录</li>
<li>根据上面的观察，我们可以给出一个构造run的算法。这个技术通常被叫做replacement selection。初始的情况，m条记录被读入内存，并且放进一个优先队列。然后我们执行delete_min，将最小的记录写到输出磁带，然后我们从输入磁带中读入下一个记录到内存，如果这条记录比上一条写到磁带中的记录要大，那么它就可以加入到内存中的优先队列中，否则，这个记录不能放到现在正在构造的run中（因为这样会破坏排列顺序），由于优先队列长度减1，此时我们可以将新读到内存中的元素放到现在优先队列没有用到的内存中，直到现在这个优先队列构造的run完成之后，放在内存中没有用到的元素又可以用来构造下一个优先队列，存储优先队列没有用到的数据的方式和堆排序类似。重复这个过程知道优先队列的大小为0，然后我们通过使用原来优先队列没用到的数据建立一个新的优先队列来重新开始构造新的run</li>
<li>如果输入是随机的，那么可以证明replacement selection可以构造平均长度为2m的run（m为内存一次可以读入的记录数），所以整个需要构造的run的个数也减半，这样的话通过passN = ┌logk (A)┐（passN为pass次数，A为runs的个数），可能减少pass的次数，由于访问外村非常耗时，所以每减少一次pass都是很有意义的</li>
<li>尽管replacement selection可能不会比普通的算法更有效，但是由于输入数据经常是已排序的或者接近排好序的，这个时候如果使用replacement selection我们就可以构造一些很长的runs，从而可以减少pass数量，从而可以减少外排时间，由于这样的输入在外排是很常见的，这使得replacement selection变得很有价值</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>
    
    <footer>
      <div class="alignleft">
      
  
  <div class="categories">
    <a href="/categories/Algorithm/">Algorithm</a>
  </div>

      
  
  <div class="tags">
    <a href="/tags/sort/">sort</a>
  </div>

      </div>
      <div class="clearfix"></div>
    </footer>
    
  </div>
</article>


<section id="comment">
  
            <!-- Duoshuo Comment BEGIN -->
            <div class="ds-thread"></div>
            <script type="text/javascript">
                var duoshuoQuery = {short_name:"jjliu"};
                (function() {
                    var ds = document.createElement('script');
                    ds.type = 'text/javascript';ds.async = true;
                    ds.src = 'http://static.duoshuo.com/embed.js';
                    ds.charset = 'UTF-8';
                    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ds);
                })();
            </script>
            <!-- Duoshuo Comment END -->
      
  
</section>

</div></div>
    <div class="clearfix"></div>
  </div>
  <footer id="footer"><div class="inner"><div class="alignleft">
  <p>
  
    &copy; 2014 Jin Liu
  
  </p>
  <p>
   Theme By <a href="http://www.jjliu.tk" >Jin</a>
   based on <a href="http://github.com/willerce/hexo-theme-noderce">Noderce</a>
  </p>

</div>
<div class="clearfix"></div>
</div></footer>
  <script type="text/javascript">

</script>

</body>
</html>
